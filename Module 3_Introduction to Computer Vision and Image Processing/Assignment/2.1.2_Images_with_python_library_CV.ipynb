{"cells":[{"cell_type":"markdown","id":"fe5c6917-35d9-4c26-832b-ed182f920027","metadata":{},"outputs":[],"source":["<p>\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"7b3f3314-7685-43bf-89c3-52ca366fee95","metadata":{},"outputs":[],"source":["# OpenCV Library\n"]},{"cell_type":"markdown","id":"942cd296-fec7-4be0-8ad3-2103a69678c8","metadata":{},"outputs":[],"source":["Estimated time needed: **60** minutes\n"]},{"cell_type":"markdown","id":"e9334e3b-8b67-4453-978b-b2b74abe9a2c","metadata":{},"outputs":[],"source":["<h2>Objectives</h2>\n"]},{"cell_type":"markdown","id":"d3f6ae59-f784-47a0-9884-8c1193a73a9a","metadata":{},"outputs":[],"source":["Image processing and computer vision tasks include displaying, cropping, flipping, rotating,  image segmentation, classification, image restoration,  image recognition, image generation.  Also, working with images via the cloud requires storing and transmitting, and gathering images through the internet. \n","Python is an excellent choice as it has many image processing tools, computer vision, and artificial intelligence libraries. Finally, it has many libraries for working with files in the cloud and the internet.\n","A digital image is simply a file on your computer. In this lab, you will gain an understanding  of these files and learn to work with these files with some popular libraries\n"]},{"cell_type":"markdown","id":"833c68c8-16df-4e1a-a987-bc802a5133d8","metadata":{},"outputs":[],"source":["<ul>\n","    <li><a href='#PIL'>Open CV </a>\n","        <ul>\n","            <li>Image Files and Paths  </li>\n","            <li>Load in Image in Python</li>\n","            <li>Plotting an Image </li>\n","            <li>Gray Scale Images, Quantization and Color Channels  </li>\n","            <li>Gray Scale Images, Quantization and Color Channels  </li>\n","        </ul>\n","    </li>\n","    \n","</ul>\n"]},{"cell_type":"markdown","id":"d9bf40bf-234b-457a-ada7-c9d1dc883d37","metadata":{},"outputs":[],"source":["----\n"]},{"cell_type":"markdown","id":"edb24220-07e0-4449-8eba-bb0042b8fde7","metadata":{},"outputs":[],"source":["Download the image for the lab:\n"]},{"cell_type":"code","id":"5272dc42-a35b-407c-86a8-a7174dcc49d3","metadata":{},"outputs":[],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/lenna.png -O lenna.png\n!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/baboon.png -O baboon.png\n!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/barbara.png -O barbara.png  "]},{"cell_type":"markdown","id":"bfc58b1d-a4d3-44bc-8c2b-ff249789d555","metadata":{},"outputs":[],"source":["First, let's define a helper function to concatenate two images side-by-side. You will need to understand this code this moment, but this function will be used repeatedly in this tutorial to showcase the results.\n"]},{"cell_type":"code","id":"a77612db-d17f-4c92-964e-2f674e0f6042","metadata":{},"outputs":[],"source":["def get_concat_h(im1, im2):\n    #https://note.nkmk.me/en/python-pillow-concat-images/\n    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n    dst.paste(im1, (0, 0))\n    dst.paste(im2, (im1.width, 0))\n    return dst"]},{"cell_type":"markdown","id":"4bbd9698-5558-431b-b2c6-c7759a98adec","metadata":{},"outputs":[],"source":["## Image Files and Paths  \n"]},{"cell_type":"markdown","id":"9e5f0519-ccaa-4c70-abc9-8cf360c3414a","metadata":{},"outputs":[],"source":["An image is stored as a file on your computer. Below, we define `my_image` as the filename of a file in this directory.\n"]},{"cell_type":"code","id":"927fb375-291d-4f7f-8fe6-dc3f273727e8","metadata":{},"outputs":[],"source":["my_image = \"lenna.png\""]},{"cell_type":"markdown","id":"ccd24e82-67d5-40d2-9277-d2c91b9b843a","metadata":{},"outputs":[],"source":["Filename consists of two parts, the name of the file and the extension, separated by a full stop (`.`). The extension specifies the format of the image. There are two popular image formats -- Joint Photographic Expert Group image (or `.jpg`, `.jpeg`) and Portable Network Graphics (or `.png`). These file types make it simpler to work with images. For example, it compresses the image using sine/cosine approximations, taking less spaces on your drive to store the image.\n"]},{"cell_type":"markdown","id":"c2b4c826-14bc-43c3-ab11-d16591761a88","metadata":{},"outputs":[],"source":["Image files are stored in the file system of your computer. The location of it is specified using a \"path\", which is often unique. You can find the path of your current working directory with Python's `os` module. The `os` module provides functions to interact with the file system, e.g. creating or removing a directory (folder), listing its contents, changing and identifying the current working directory. \n"]},{"cell_type":"code","id":"b2416d11-71ee-4881-a18a-facb51accac5","metadata":{},"outputs":[],"source":["import os\ncwd = os.getcwd()\ncwd "]},{"cell_type":"markdown","id":"77d7fd68-6384-4321-b65e-3298e9115d91","metadata":{},"outputs":[],"source":["The \"path\" to an image can be found using the following line of code.\n"]},{"cell_type":"code","id":"97f26328-dd54-4f36-beaf-f1c70fdba253","metadata":{},"outputs":[],"source":["image_path = os.path.join(cwd, my_image)\nimage_path"]},{"cell_type":"markdown","id":"f598b08b-6c3a-4882-b973-52d8b1ee1c5e","metadata":{},"outputs":[],"source":["## Load in Image in Python\n"]},{"cell_type":"markdown","id":"37db9948-f89a-47a7-afd1-29ba5de69c18","metadata":{},"outputs":[],"source":["OpenCV is a library used for computer vision. It has more functionality than the `PIL` library but is more difficult to use. We can import `OpenCV` as follows:\n"]},{"cell_type":"code","id":"c55a7ef3-0378-42bc-bd26-14382f707a3a","metadata":{},"outputs":[],"source":["import cv2"]},{"cell_type":"markdown","id":"ec9020db-6736-42ad-bfa6-ddb74a7eaa2f","metadata":{},"outputs":[],"source":["The <code>imread()</code> method loads an image from the specified file, the input is the <code>path</code> of the image to be read (just like PIL), the <code>flag</code> paramter specifies how the image should be read, and the default value is <code>cv2.IMREAD_COLOR</code>.\n"]},{"cell_type":"code","id":"abf39a75-648d-4100-a7c0-8297ab631fb7","metadata":{},"outputs":[],"source":["image = cv2.imread(my_image)"]},{"cell_type":"markdown","id":"22064fd3-0928-4494-9ab1-88456f185a57","metadata":{},"outputs":[],"source":["The result is a numpy array with intensity values as 8-bit unsigned integers. \n"]},{"cell_type":"code","id":"7fc8b3e7-ebcd-49c4-9d42-363c9dbe6914","metadata":{},"outputs":[],"source":["type(image)"]},{"cell_type":"markdown","id":"e3778765-e9df-4986-82f8-1a2479156573","metadata":{},"outputs":[],"source":["We can get the shape of the array from the `shape` attribute.\n"]},{"cell_type":"code","id":"8bc705d8-e886-4d71-b5d7-acc7bc63002f","metadata":{},"outputs":[],"source":["image.shape"]},{"cell_type":"markdown","id":"624d312d-9b5b-4057-bc83-f08ac75f14b2","metadata":{},"outputs":[],"source":["The shape is the same as the PIL array, but there are several differences; for example, PIL returns in (R, G, B) format whereas OpenCV returns in (B, G, R) format.\n"]},{"cell_type":"markdown","id":"226bcff2-7479-406d-86be-8ef99dd984fa","metadata":{},"outputs":[],"source":["Each pixel could take on 256 possible values as intensity, ranging from 0 to 255, with 0 being the lowest intensity and 255 being the highest. The maximum and minimum intensity values of an image can be obtained, respectively, by calling:\n"]},{"cell_type":"code","id":"7c76d9c6-01a0-47d0-b186-71d8811adfa0","metadata":{},"outputs":[],"source":["image.max()"]},{"cell_type":"markdown","id":"48dc81b6-6b8f-40be-a817-c667ad02fbd5","metadata":{},"outputs":[],"source":["and\n"]},{"cell_type":"code","id":"a4f7076e-7e80-469d-81a0-89a30eae7927","metadata":{},"outputs":[],"source":["image.min()"]},{"cell_type":"markdown","id":"f1222f33-3fd3-47f4-bad3-17aaffec5901","metadata":{},"outputs":[],"source":["##  Plotting an Image \n"]},{"cell_type":"markdown","id":"a9bae67a-0cd5-4405-8a79-6de3421cc7cc","metadata":{},"outputs":[],"source":["You can use OpenCV's `imshow` function to open the image in a new window, but this may give you some issues in Jupyter:\n"]},{"cell_type":"code","id":"a2c772b5-7c6a-4da5-a025-4a7fbf4e2ccc","metadata":{},"outputs":[],"source":["#cv2.imshow('image', imgage)\n#cv2.waitKey(0)\n#cv2.destroyAllWindows()"]},{"cell_type":"markdown","id":"2bc74bb1-c3c2-4d8a-8c75-8dfa9d347cc6","metadata":{},"outputs":[],"source":["You can also use the `imshow` function from the `matplotlib` library:\n"]},{"cell_type":"code","id":"69d4d479-b17c-42b0-b10b-27a5b8e0fecd","metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt"]},{"cell_type":"code","id":"802b459f-cbcd-439c-850c-25e85032133e","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.imshow(image)\nplt.show()"]},{"cell_type":"markdown","id":"fc8adac4-2859-41a5-bd7a-26d3310c000f","metadata":{},"outputs":[],"source":["The image output doesn't look natural. This is because the order of RGB Channels are different. We can change the color space with conversion code and the function `cvtColor` from the `cv2` library:\n"]},{"cell_type":"code","id":"80361372-2094-4a2c-b806-08241cac3845","metadata":{},"outputs":[],"source":["new_image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"]},{"cell_type":"code","id":"a101c890-de40-43a3-850a-771c6a808550","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.imshow(new_image)\nplt.show()"]},{"cell_type":"markdown","id":"2555bc96-2efc-4bfa-838e-0c7ce44c7f52","metadata":{},"outputs":[],"source":["You can also load the image using its path, this comes in handy if the image is not in your working directory:\n"]},{"cell_type":"code","id":"0b451862-a191-4b36-92ad-fa167ca2f18a","metadata":{},"outputs":[],"source":["image = cv2.imread(image_path)\nimage.shape"]},{"cell_type":"markdown","id":"1b9d2431-d814-45b2-a495-d8ba1fabbe08","metadata":{},"outputs":[],"source":["You can save the image as in `jpg` format.\n"]},{"cell_type":"code","id":"f8e6c869-bcde-449b-8c02-c2dfe8e75fdf","metadata":{},"outputs":[],"source":["cv2.imwrite(\"lenna.jpg\", image)"]},{"cell_type":"markdown","id":"e29f99c6-d5a2-45df-b24e-2c9e1be92eff","metadata":{},"outputs":[],"source":["### Grayscale Images\n"]},{"cell_type":"markdown","id":"658ce16f-39f1-4b8c-b1ea-eca5b18d0d0b","metadata":{},"outputs":[],"source":["Grayscale images have pixel values representing the amount of light or intensity. Light shades of gray have a high-intensity darker shades have a lower intensity. White has the highest intensity, and black the lowest. We can convert an image to Gray Scale using a color conversion code and the function <code>cvtColor</code>.\n"]},{"cell_type":"markdown","id":"6c1562cb-b85c-4095-91cf-1008138c37fa","metadata":{},"outputs":[],"source":["The code for RGB to gray is <code>cv2.COLOR_BGR2GRAY</code>, we apply the function:\n"]},{"cell_type":"code","id":"054e9a17-acec-49cb-8e13-b45e901de2b2","metadata":{},"outputs":[],"source":["image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"]},{"cell_type":"markdown","id":"38c226b7-c147-465d-980b-24c48f1dbcf4","metadata":{},"outputs":[],"source":["The image array has only two dimensions, i.e. only one color channel:\n"]},{"cell_type":"code","id":"5594266f-c094-4eef-9699-f629f8494722","metadata":{},"outputs":[],"source":["image_gray.shape"]},{"cell_type":"markdown","id":"a92780c0-9c91-49cb-aaed-1a6f720b6f40","metadata":{},"outputs":[],"source":["We can plot the image using `imshow` but we have to specify the color map is gray:\n"]},{"cell_type":"code","id":"aea08268-6533-4b28-8ba5-536ef6d8d922","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10, 10))\nplt.imshow(image_gray, cmap='gray')\nplt.show()"]},{"cell_type":"markdown","id":"66d3933f-f00f-4001-935f-304afbeb2a3f","metadata":{},"outputs":[],"source":["We can save the image as a grayscale image, let's save it as a `jpg` as well, in the working directory.\n"]},{"cell_type":"code","id":"7ce6f44c-2f51-4835-a7e5-b06448267cb8","metadata":{},"outputs":[],"source":["cv2.imwrite('lena_gray_cv.jpg', image_gray)"]},{"cell_type":"markdown","id":"97c790f1-7c0f-4e9c-8cc0-711df4dfc837","metadata":{},"outputs":[],"source":["You can also load in a grayscale image we have to set <code>flag</code> parameter to gray color conversation code: <code>cv2.COLOR_BGR2GRAY</code>:\n"]},{"cell_type":"code","id":"823e1170-457e-495d-952b-94fdfa051e2b","metadata":{},"outputs":[],"source":["im_gray = cv2.imread('barbara.png', cv2.IMREAD_GRAYSCALE)"]},{"cell_type":"markdown","id":"1bb8d98d-484f-4a25-b69f-ecf3bebe9b18","metadata":{},"outputs":[],"source":["We can plot the image:\n"]},{"cell_type":"code","id":"739a5c5a-fbc1-4e74-b601-16c96ca7a3f9","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.imshow(im_gray,cmap='gray')\nplt.show()"]},{"cell_type":"markdown","id":"9d5bbf06-bdad-4645-b91f-65212a1f2bd4","metadata":{},"outputs":[],"source":["### Color Channels  \n"]},{"cell_type":"markdown","id":"574830c7-19e3-4b18-b8e8-da57d714f7b0","metadata":{},"outputs":[],"source":["We can also work with the different color channels. Consider the following image:\n"]},{"cell_type":"code","id":"96ce59fa-6e63-438b-8d99-bdeaaf489907","metadata":{},"outputs":[],"source":["baboon=cv2.imread('baboon.png')\nplt.figure(figsize=(10,10))\nplt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"6f37b922-709f-4b38-aef4-9cd61990608f","metadata":{},"outputs":[],"source":["We can obtain the different RGB colors and assign them to the variables <code>blue</code>, <code>green</code>, and <code>red</code>, in (B, G, R) format.\n"]},{"cell_type":"code","id":"baf7659a-92d6-49d1-a8af-8a25985ed976","metadata":{},"outputs":[],"source":["blue, green, red = baboon[:, :, 0], baboon[:, :, 1], baboon[:, :, 2]"]},{"cell_type":"markdown","id":"36500b9c-af8e-4943-9a70-589fa76e4c11","metadata":{},"outputs":[],"source":["We can concatenate each image channel the images using the function <code>vconcat</code>.\n"]},{"cell_type":"code","id":"cbb89d78-af41-41e9-a2cd-99cd47397176","metadata":{},"outputs":[],"source":["im_bgr = cv2.vconcat([blue, green, red])"]},{"cell_type":"markdown","id":"88dbbee3-cdde-46fd-bdda-f05c4d9afd6b","metadata":{},"outputs":[],"source":["Plotting the color image next to the red channel in grayscale, we see that regions with red have higher intensity values.\n"]},{"cell_type":"code","id":"69914f1a-29f0-40aa-9910-86613e752e54","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.subplot(121)\nplt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\nplt.title(\"RGB image\")\nplt.subplot(122)\nplt.imshow(im_bgr,cmap='gray')\nplt.title(\"Different color channels  blue (top), green (middle), red (bottom)  \")\nplt.show()"]},{"cell_type":"markdown","id":"41e1ee0a-d5db-4b84-8ae0-9305e3a8803f","metadata":{},"outputs":[],"source":["### Indexing  \n"]},{"cell_type":"markdown","id":"fa12ba04-9662-40f8-835c-67302c9d36df","metadata":{},"outputs":[],"source":["We can use numpy slicing. For example, we can return the first 256 rows corresponding to the top half of the image:\n"]},{"cell_type":"code","id":"79ec67ce-27d7-44de-9d5e-bd653f8f666a","metadata":{},"outputs":[],"source":["rows = 256"]},{"cell_type":"code","id":"cf6ee50a-ee58-4610-80fe-f251e1ef0524","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.imshow(new_image[0:rows,:,:])\nplt.show()"]},{"cell_type":"markdown","id":"7d7a013a-a4a3-4cb3-a83f-1368dde98398","metadata":{},"outputs":[],"source":["We can also return the first 256 columns corresponding to the first half of the image:\n"]},{"cell_type":"code","id":"e6e09691-ffc3-40ba-9e6b-a7d748502d55","metadata":{},"outputs":[],"source":["columns = 256"]},{"cell_type":"code","id":"4ddc6f6a-5854-464c-8828-bd7ba02d8bd0","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.imshow(new_image[:,0:columns,:])\nplt.show()"]},{"cell_type":"markdown","id":"14189ebb-9d6c-48c5-b357-e544526d375b","metadata":{},"outputs":[],"source":["If you want to reassign an array to another variable, you should use the `copy` method (we will cover this in the next section).\n"]},{"cell_type":"code","id":"c736992a-fadc-4cf9-b34d-302e1817d931","metadata":{},"outputs":[],"source":["A = new_image.copy()\nplt.imshow(A)\nplt.show()"]},{"cell_type":"markdown","id":"8ffe3022-79b2-4406-93d9-823fc276a2fe","metadata":{},"outputs":[],"source":["If we do not apply the method `copy()`, the variable will point to the same location in memory. Consider the variable `B` below, if we set all values of array `A` to zero, since `A` and `B` points to the same object in the memory, `B` will also have all-zero elements:\n"]},{"cell_type":"code","id":"613ef080-49ef-4481-9b7f-b5923795efee","metadata":{},"outputs":[],"source":["B = A\nA[:,:,:] = 0\nplt.imshow(B)\nplt.show()"]},{"cell_type":"markdown","id":"61bbbdb2-f81c-416f-8688-c6f16c288f2b","metadata":{},"outputs":[],"source":["We can also manipulate elements using indexing. In the following piece of code, we create a new array `baboon_red` and set all but the red color channels to zero. Therefore, when we display the image, it appears red:\n"]},{"cell_type":"code","id":"93288d96-1dc6-45e3-89d5-d9d8c71b4436","metadata":{},"outputs":[],"source":["baboon_red = baboon.copy()\nbaboon_red[:, :, 0] = 0\nbaboon_red[:, :, 1] = 0\nplt.figure(figsize=(10, 10))\nplt.imshow(cv2.cvtColor(baboon_red, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"ee71be13-ab92-4628-b10e-aad3203cd784","metadata":{},"outputs":[],"source":["We can do the same for blue:  \n"]},{"cell_type":"code","id":"ea41b8c8-6574-4dd8-af75-1cc86c042000","metadata":{},"outputs":[],"source":["baboon_blue = baboon.copy()\nbaboon_blue[:, :, 1] = 0\nbaboon_blue[:, :, 2] = 0\nplt.figure(figsize=(10, 10))\nplt.imshow(cv2.cvtColor(baboon_blue, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"558237ec-b22a-47ee-953c-544ec8340f02","metadata":{},"outputs":[],"source":["We can do the same for green:\n"]},{"cell_type":"code","id":"30340fe2-751d-4f64-be20-a29372ac6d45","metadata":{},"outputs":[],"source":["baboon_green = baboon.copy()\nbaboon_green[:, :, 0] = 0\nbaboon_green[:, :, 2] = 0\nplt.figure(figsize=(10,10))\nplt.imshow(cv2.cvtColor(baboon_green, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"code","id":"96b97194-10c6-4ec6-b3a3-2145c2fc3e4d","metadata":{},"outputs":[],"source":["image=cv2.imread('baboon.png')"]},{"cell_type":"code","id":"fdd1ef58-ee62-4fc9-99ed-dc1d57938926","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"code","id":"dea12fa5-83c6-477c-a072-a8f71137522f","metadata":{},"outputs":[],"source":["image=cv2.imread('baboon.png') # replace and add you image here name \nbaboon_blue=image.copy()\nbaboon_blue[:,:,1] = 0\nbaboon_blue[:,:,2] = 0\nplt.figure(figsize=(10,10))\nplt.imshow(cv2.cvtColor(baboon_blue, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"b666541c-f62b-498c-a1b5-860b4379fed9","metadata":{},"outputs":[],"source":["### Question 1: \n","Use the image `baboon.png` from this lab or take any image you like.\n","\n","Open the image and create a OpenCV Image object called `baboon_blue`, convert the image from BGR format to RGB format, get the blue channel out of it, and finally plot the image\n"]},{"cell_type":"code","id":"f1e42b0f-89d1-4ca9-8d19-6e873333e5b0","metadata":{},"outputs":[],"source":["# write your script here\n"]},{"cell_type":"markdown","id":"a912bb7f-1fe9-4a31-b141-8550828d671e","metadata":{},"outputs":[],"source":["Double-click **here** for a hint.\n","\n","<!-- The hint is below:\n","\n","baboon_blue[:,:,2] = 0\n","\n","-->\n"]},{"cell_type":"markdown","id":"61c461af-319e-4779-9191-8e77ff8493c5","metadata":{},"outputs":[],"source":["Double-click **here** for the solution.\n","\n","<!-- The answer is below:\n","\n","baboon_blue=cv2.imread('baboon.png')\n","baboon_blue=cv2.cvtColor(baboon_blue, cv2.COLOR_BGR2RGB)\n","baboon_blue[:,:,2] = 0\n","plt.figure(figsize=(10,10))\n","plt.imshow(baboon_blue)\n","plt.show()\n","\n","-->\n"]},{"cell_type":"markdown","id":"4f6415a9-c964-45c3-bea4-ed972046da82","metadata":{},"outputs":[],"source":["<h2>Authors</h2>\n"]},{"cell_type":"markdown","id":"0f494a89-ba9e-4007-9b0b-c6a7aecb9a01","metadata":{},"outputs":[],"source":[" [Joseph Santarcangelo]( https://www.linkedin.com/in/joseph-s-50398b136/) has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"]},{"cell_type":"markdown","id":"779d191a-2272-4c79-946e-e8aed648918c","metadata":{},"outputs":[],"source":[" [Nayef Abou Tayoun](https://www.linkedin.com/in/nayefaboutayoun/) has a master of management in artificial intelligence degree, focusing on using machine learning and computer vision.   \n"]},{"cell_type":"markdown","id":"be871ae9-1c9e-4657-87d5-7ac37de23693","metadata":{},"outputs":[],"source":["# References \n"]},{"cell_type":"markdown","id":"0f30d4f3-c5b5-464e-847d-4924d0ed28ce","metadata":{},"outputs":[],"source":["[1]  Images were taken from: https://homepages.cae.wisc.edu/~ece533/images/\n","    \n","[2]  <a href='https://pillow.readthedocs.io/en/stable/index.html'>Pillow Docs</a>\n","\n","[3]  <a href='https://opencv.org/'>Open CV</a>\n","\n","[4] Gonzalez, Rafael C., and Richard E. Woods. \"Digital image processing.\" (2017).\n"]},{"cell_type":"markdown","id":"596184f3-4901-4276-9748-33e774026f71","metadata":{},"outputs":[],"source":["<!--<h2>Change Log</h2>-->\n"]},{"cell_type":"markdown","id":"5252dbd0-58fd-42f0-a9ec-1d6ac5918db3","metadata":{},"outputs":[],"source":["<!--\n","<table>\n","    <tr>\n","        <th>Date (YYYY-MM-DD)</th>\n","        <th>Version</th>\n","        <th>Changed By</th>\n","        <th>Change Description</th>\n","    </tr>\n","    <tr>\n","        <td>2020-07-20</td>\n","        <td>0.2</td>\n","        <td>Azim</td>\n","        <td>Modified Multiple Areas</td>\n","    </tr>\n","    <tr>\n","        <td>2020-07-17</td>\n","        <td>0.1</td>\n","        <td>Azim</td>\n","        <td>Created Lab Template</td>\n","    </tr>\n","    <tr>\n","        <td>2021-03-06</td>\n","        <td>0.3</td>\n","        <td>Nayef</td>\n","        <td>Modified some codes</td>\n","    </tr>\n","</table>\n","-->\n"]},{"cell_type":"markdown","id":"f56ff959-4d73-4e2a-a99c-bef380f5fac6","metadata":{},"outputs":[],"source":["<h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"prev_pub_hash":"91d5559200847c55b7d64280c67a707ba71a4a95c1bedd1accf229de1a66c9c0"},"nbformat":4,"nbformat_minor":4}