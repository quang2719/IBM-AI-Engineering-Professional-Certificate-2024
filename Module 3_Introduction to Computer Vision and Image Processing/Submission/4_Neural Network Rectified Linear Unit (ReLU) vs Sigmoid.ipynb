{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Neural Network Rectified Linear Unit (ReLU) vs Sigmoid</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Objective for this Notebook<h3>    \n",
    "<h5> 1. Define Several Neural Network, Criterion function, Optimizer.</h5>\n",
    "<h5> 2. Test Sigmoid and Relu. </h5>\n",
    "<h5> 3. Analyze Results. </h5>     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<p>In this lab, you will test Sigmoid and Relu activation functions on the MNIST dataset with two hidden Layers.</p>\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#Model\">Neural Network Module and Training Function</a></li>\n",
    "    <li><a href=\"#Makeup_Data\">Make Some Data</a></li>\n",
    "    <li><a href=\"#Train\">Define Several Neural Network, Criterion function, Optimizer</a></li>\n",
    "    <li><a href=\"#Test\">Test Sigmoid and Relu </a></li>\n",
    "    <li><a href=\"#Result\">Analyze Results</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>25 min</strong></p>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the following libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (1.13.1+cpu)\n",
      "Requirement already satisfied: torchvision in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (0.14.1+cpu)\n",
      "Requirement already satisfied: torchaudio in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (0.13.1+cpu)\n",
      "Requirement already satisfied: typing-extensions in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: numpy in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from torchvision) (8.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests->torchvision) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f02d5dcadb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the libraries we need for this lab\n",
    "\n",
    "# Using the following line code to install the torchvision library\n",
    "# !conda install -y torchvision\n",
    "\n",
    "# PyTorch Library\n",
    "import torch \n",
    "# PyTorch Neural Network\n",
    "import torch.nn as nn\n",
    "# Allows us to transform tensors\n",
    "import torchvision.transforms as transforms\n",
    "# Allows us to download datasets\n",
    "import torchvision.datasets as dsets\n",
    "# Allows us to use activation functions\n",
    "import torch.nn.functional as F\n",
    "# Used to graph data and loss curves\n",
    "import matplotlib.pylab as plt\n",
    "# Allows us to use arrays to manipulate and store data\n",
    "import numpy as np\n",
    "# Setting the seed will allow us to control randomness and give us reproducibility\n",
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Model\">Neural Network Module and Training Function</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network module or class, with two hidden Layers \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ibm.box.com/shared/static/5wtclahun0f70qlwkn2kxzh3amnbq4zg.png\" width=\"200\" alt=\"Neural Network Model\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the model class using Sigmoid as the activation function\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        # D_in is the input size of the first layer (size of input layer)\n",
    "        # H1 is the output size of the first layer and input size of the second layer (size of first hidden layer)\n",
    "        # H2 is the outpout size of the second layer and the input size of the third layer (size of second hidden layer)\n",
    "        # D_out is the output size of the third layer (size of output layer)\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self,x):\n",
    "        # Puts x through the first layers then the sigmoid function\n",
    "        x = torch.sigmoid(self.linear1(x)) \n",
    "        # Puts results of previous line through second layer then sigmoid function\n",
    "        x = torch.sigmoid(self.linear2(x))\n",
    "        # Puts result of previous line through third layer\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the class for the Relu activation function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the model class using Relu as the activation function\n",
    "\n",
    "class NetRelu(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        # D_in is the input size of the first layer (size of input layer)\n",
    "        # H1 is the output size of the first layer and input size of the second layer (size of first hidden layer)\n",
    "        # H2 is the outpout size of the second layer and the input size of the third layer (size of second hidden layer)\n",
    "        # D_out is the output size of the third layer (size of output layer)\n",
    "        super(NetRelu, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        # Puts x through the first layers then the relu function\n",
    "        x = torch.relu(self.linear1(x))  \n",
    "        # Puts results of previous line through second layer then relu function\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        # Puts result of previous line through third layer\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to  train the model, in this case, the function returns a Python dictionary to store the training loss and accuracy on the validation data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Training Function\n",
    "\n",
    "def train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n",
    "    i = 0\n",
    "    useful_stuff = {'training_loss': [], 'validation_accuracy': []}  \n",
    "    # Number of times we train on the entire training dataset\n",
    "    for epoch in range(epochs):\n",
    "        # For each batch in the train loader\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            # Resets the calculated gradient value, this must be done each time as it accumulates if we do not reset\n",
    "            optimizer.zero_grad()\n",
    "            # Makes a prediction on the image tensor by flattening it to a 1 by 28*28 tensor\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            # Calculate the loss between the prediction and actual class\n",
    "            loss = criterion(z, y)\n",
    "            # Calculates the gradient value with respect to each weight and bias\n",
    "            loss.backward()\n",
    "            # Updates the weight and bias according to calculated gradient value\n",
    "            optimizer.step()\n",
    "            # Saves the loss\n",
    "            useful_stuff['training_loss'].append(loss.data.item())\n",
    "        \n",
    "        # Counter to keep track of correct predictions\n",
    "        correct = 0\n",
    "        # For each batch in the validation dataset\n",
    "        for x, y in validation_loader:\n",
    "            # Make a prediction\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            # Get the class that has the maximum value\n",
    "            _, label = torch.max(z, 1)\n",
    "            # Check if our prediction matches the actual class\n",
    "            correct += (label == y).sum().item()\n",
    "    \n",
    "        # Saves the percent accuracy\n",
    "        accuracy = 100 * (correct / len(validation_dataset))\n",
    "        useful_stuff['validation_accuracy'].append(accuracy)\n",
    "    \n",
    "    return useful_stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Makeup_Data\">Make Some Data</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset by setting the parameters <code>train</code> to <code>True</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10710f597ec43b0a0c9f8f4179f9fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bfa740fe964bfbab84a808063ae3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5adcdd347f9a450eb16bb0fddd4843c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825418acb0974de883914ee5fac0de3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the training dataset\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the testing dataset by setting the parameters <code>train</code> to <code>False</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the validating dataset\n",
    "\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the criterion function  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the criterion function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training-data loader and the validation-data loader object \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the training data loader and validation data loader object\n",
    "\n",
    "# Batch size is 2000 and shuffle=True means the data will be shuffled at every epoch\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\n",
    "# Batch size is 5000 and the data will not be shuffled at every epoch\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Train\">Define Neural Network, Criterion function, Optimizer and Train the Model</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create  the model with 100 hidden neurons  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the parameters to create the model\n",
    "\n",
    "input_dim = 28 * 28 # Diemension of an image\n",
    "hidden_dim1 = 50\n",
    "hidden_dim2 = 50\n",
    "output_dim = 10 # Number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The epoch number in the video is 35. You can try 10 for now. If you try 35, it may take a long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the number of iterations\n",
    "\n",
    "cust_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Test\">Test Sigmoid and Relu</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network using the Sigmoid activation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model with sigmoid function\n",
    "\n",
    "learning_rate = 0.01\n",
    "# Create an instance of the Net model\n",
    "model = Net(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "# Create an optimizer that updates model parameters using the learning rate and gradient\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# Train the model\n",
    "training_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=cust_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network using the Relu activation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model with relu function\n",
    "\n",
    "learning_rate = 0.01\n",
    "# Create an instance of the NetRelu model\n",
    "modelRelu = NetRelu(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "# Create an optimizer that updates model parameters using the learning rate and gradient\n",
    "optimizer = torch.optim.SGD(modelRelu.parameters(), lr=learning_rate)\n",
    "# Train the model\n",
    "training_results_relu = train(modelRelu, criterion, train_loader, validation_loader, optimizer, epochs=cust_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Result\">Analyze Results</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the training loss for each activation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare the training loss\n",
    "\n",
    "plt.plot(training_results['training_loss'], label='sigmoid')\n",
    "plt.plot(training_results_relu['training_loss'], label='relu')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training loss iterations')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the validation loss for each model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare the validation loss\n",
    "\n",
    "plt.plot(training_results['validation_accuracy'], label = 'sigmoid')\n",
    "plt.plot(training_results_relu['validation_accuracy'], label = 'relu') \n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('Iteration')   \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_source=Exinfluencer&utm_content=000026UJ&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01&utm_medium=Exinfluencer&utm_term=10006555&context=cpdaas&apps=data_science_experience%2Cwatson_machine_learning\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera872-2023-01-01\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-09-23  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> Â© IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
